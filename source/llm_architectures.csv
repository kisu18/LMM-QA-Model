Model,Year,Paper
BERT,2018,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
GPT-3,2020,Language Models are Few-Shot Learners
T5,2019,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
